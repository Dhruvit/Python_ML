{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Movie genre Prediction.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhruvit/Python_ML/blob/master/Movie_genre_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxDCqW8cfgdM",
        "colab_type": "text"
      },
      "source": [
        "Multi lebal movie classification\n",
        "we will use python code to do this\n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2019/04/predicting-movie-genres-nlp-multi-label-classification/?utm_source=blog&utm_medium=7-innovative-machine-learning-github-projects-in-python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM_LNvMhfo_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tarfile\n",
        "movie_tar_data = tarfile.open('/content/MovieSummaries.tar.gz')\n",
        "movie_tar_data.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5H0c6uziDAZ",
        "colab_type": "code",
        "outputId": "19bfeb2a-291a-4a79-fe4e-ca69d654427b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import nltk\n",
        "import re\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%matplotlib inline\n",
        "pd.set_option('display.max_colwidth', 300)\n",
        "\n",
        "meta = pd.read_csv('/content/MovieSummaries/movie.metadata.tsv', sep='\\t', header=None)\n",
        "meta.head()\n",
        "\n",
        "# There is no header, we need to add header\n",
        "\n",
        "# rename columns\n",
        "meta.columns = [\"movie_id\",1,\"movie_name\",3,4,5,6,7,\"genre\"]\n",
        "\n",
        "#Now, we will load the movie plot dataset into memory. This data comes in a text file with each row consisting of a movie id and a plot of the movie. We will read it line-by-line:\n",
        "\n",
        "plots = []\n",
        "\n",
        "with open(\"/content/MovieSummaries/plot_summaries.txt\", 'r') as f:\n",
        "  reader = csv.reader(f, dialect = 'excel-tab')\n",
        "  for row in tqdm(reader): #TODO: need to know more about tqdm\n",
        "    plots.append(row)\n",
        "    \n",
        "#Next, split the movie ids and the plots into two separate lists. We will use these lists to form a dataframe:\n",
        "movie_id = []\n",
        "plot = []\n",
        "\n",
        "# extract movie Ids and plot summaries\n",
        "for i in tqdm(plots):\n",
        "  movie_id.append(i[0])\n",
        "  plot.append(i[1])\n",
        "\n",
        "# create dataframe\n",
        "movies = pd.DataFrame({'movie_id': movie_id, 'plot': plot})\n",
        "\n",
        "movies.head()\n",
        "\n",
        "#Perfect! We have both the movie id and the corresponding movie plot\n",
        "\n",
        "# Data Exploration and Pre-processing\n",
        "\n",
        "# change datatype of 'movie-id'\n",
        "meta['movie_id'] = meta['movie_id'].astype(str)\n",
        "\n",
        "# merge meta with movies\n",
        "movies = pd.merge(movies, meta[['movie_id', 'movie_name', 'genre']], on = 'movie_id')\n",
        "\n",
        "movies.head()\n",
        "\n",
        "movies['genre'][0]\n",
        "\n",
        "# convert this string into json\n",
        "\n",
        "json.loads(movies['genre'][0]).values()\n",
        "\n",
        "# and empty list\n",
        "genres = []\n",
        "\n",
        "# extract genres\n",
        "for i in movies['genre']:\n",
        "  genres.append(list(json.loads(i).values()))\n",
        "  \n",
        "# add to 'movies' dataframe\n",
        "movies['genre_new'] = genres\n",
        "\n",
        "movies.head()\n",
        "\n",
        "# Some of the samples might not contain any genre tags. We should remove those samples as they won’t play a part in our model building process:\n",
        "\n",
        "# remove sample with 0 genre tags\n",
        "movies_new = movies[~(movies['genre_new'].str.len() == 0)]\n",
        "\n",
        "movies_new.shape , movies.shape\n",
        "\n",
        "# get all genre tags in a list \n",
        "all_genres = sum(genres,[])\n",
        "len(set(all_genres))\n",
        "  \n",
        "#There are over 363 unique genre tags in our dataset. That is quite a big number. I can hardy recall 5-6 genres! Let’s find out what are these tags. We will use FreqDist( ) from the nltk library to create a dictionary of genres and their occurrence count across the dataset:\n",
        "all_genres = nltk.FreqDist(all_genres)\n",
        "\n",
        "# create dataframe\n",
        "all_genres_df = pd.DataFrame({'Genre' : list(all_genres.keys()),\n",
        "                             'Count': list(all_genres.values())})\n",
        "\n",
        "#I personally feel visualizing the data is a much better method than simply putting out numbers. So, let’s plot the distribution of the movie genres:\n",
        "'''\n",
        "g = all_genres_df.nlargest(columns=\"Count\", n = 50)\n",
        "plt.figure(figsize=(12,15))\n",
        "ax = sns.barplot(data=g,x=\"Count\",y=\"Genre\")\n",
        "ax.set(ylabel = 'Count')\n",
        "plt.show()\n",
        "'''\n",
        "\n",
        "#Next, we will clean our data a bit. I will use some very basic text cleaning steps (as that is not the focus area of this article):\n",
        "# function for text cleaning\n",
        "def clean_text(text):\n",
        "  # remove backslash-apostrophe\n",
        "  text = re.sub(\"\\'\",\"\",text)\n",
        "  # remove everything except alphabets\n",
        "  text = re.sub(\"[^a-zA-Z]\",\" \",text)\n",
        "  # remove whitespace\n",
        "  text = ' '.join(text.split())\n",
        "  #convert text to lowercase\n",
        "  text = text.lower()\n",
        "  \n",
        "  return text\n",
        "\n",
        "movies_new['clean_plot'] = movies_new['plot'].apply(lambda x: clean_text(x))\n",
        "\n",
        "movies_new.head()\n",
        "\n",
        "#The function below will visualize the words and their frequency in a set of documents. Let’s use it to find out the most frequent words in the movie plots column:\n",
        "def freq_words(x, terms = 30):\n",
        "  all_words = ' '.join([text for text in x])\n",
        "  all_words = all_words.split()\n",
        "  fdist = nltk.FreqDist(all_words)\n",
        "  words_df = pd.DataFrame({'word':list(fdist.keys()), 'count':list(fdist.values())})\n",
        "  \n",
        "  # selecting top n most frequent words\n",
        "  d = words_df.nlargest(columns=\"count\", n = terms)\n",
        "  \n",
        "  # visualize words and frequencies\n",
        "  plt.figure(figsize=(12,15))\n",
        "  ax = sns.barplot(data = d, x=\"count\", y=\"word\")\n",
        "  ax.set(ylabel='Word')\n",
        "  plt.show()\n",
        "  \n",
        "# print 100 most frequent words\n",
        "#freq_words(movies_new['clean_plot'], 100)\n",
        "\n",
        "nltk.download('stopwords')\n",
        "  \n",
        "#Let’s remove the stopwords:\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# function to remove stop words\n",
        "def remove_stopwords(text):\n",
        "  no_stopword_text = [w for w in text.split() if not w in stop_words]\n",
        "  return ' '.join(no_stopword_text)\n",
        "\n",
        "movies_new['clean_plot'] = movies_new['clean_plot'].apply(lambda x: remove_stopwords(x))\n",
        "\n",
        "#freq_words(movies_new['clean_plot'], 100)\n",
        "\n",
        "#Converting Text to Feaures\n",
        "\n",
        "#I mentioned earlier that we will treat this multi-label classification problem as a Binary Relevance problem. Hence, we will now one hot encode the target variable, i.e., genre_new by using sklearn’s MultiLabelBinarizer( ). Since there are 363 unique genre tags, there are going to be 363 new target variables.\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "multilabel_binarizer = MultiLabelBinarizer()\n",
        "multilabel_binarizer.fit(movies_new['genre_new'])\n",
        "\n",
        "# transform target variable\n",
        "y = multilabel_binarizer.transform(movies_new['genre_new'])\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=10000)\n",
        "\n",
        "# I have used the 10,000 most frequent words in the data as my features. You can try any other number as well for the max_features parameter.\n",
        "\n",
        "# split dataset into training and validation set\n",
        "xtrain, xval, ytrain, yval = train_test_split(movies_new['clean_plot'], y, test_size = 0.2, random_state=9)\n",
        "\n",
        "# Now we can create feature for the train and the validation set\n",
        "\n",
        "#create TF-IDF features\n",
        "xtrain_tfidf = tfidf_vectorizer.fit_transform(xtrain)\n",
        "xval_tfidf = tfidf_vectorizer.transform(xval)\n",
        "\n",
        "#Build Your Movie Genre Prediction Model\n",
        "#We are all set for the model building part! This is what we’ve been waiting for.\n",
        "\n",
        "#Remember, we will have to build a model for every one-hot encoded target variable. Since we have 363 target variables, we will have to fit 363 different models with the same set of predictors (TF-IDF features).\n",
        "\n",
        "#As you can imagine, training 363 models can take a considerable amount of time on a modest system. Hence, I will build a Logistic Regression model as it is quick to train on limited computational power:\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Binary Relevance\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "# Performance matric\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# We will use sk-learn’s OneVsRestClassifier class to solve this problem as a Binary Relevance or one-vs-all problem:\n",
        "\n",
        "lr = LogisticRegression()\n",
        "clf = OneVsRestClassifier(lr)\n",
        "\n",
        "# Finally, fit the model on the train set:\n",
        "# fit model on train data\n",
        "\n",
        "clf.fit(xtrain_tfidf, ytrain)\n",
        "\n",
        "# make predictions for validation set\n",
        "y_pred = clf.predict(xval_tfidf)\n",
        "\n",
        "#Let’s check out a sample from these predictions:\n",
        "\n",
        "y_pred[3]\n",
        "\n",
        "#It is a binary one-dimensional array of length 363. Basically, it is the one-hot encoded form of the unique genre tags. We will have to find a way to convert it into movie genre tags.\n",
        "\n",
        "#Luckily, sk-learn comes to our rescue once again. We will use the inverse_transform( ) function along with the MultiLabelBinarizer( ) object to convert the predicted arrays into movie genre tags:\n",
        "\n",
        "multilabel_binarizer.inverse_transform(y_pred)[3]\n",
        "\n",
        "def infer_tags(q):\n",
        "    q = clean_text(q)\n",
        "    q = remove_stopwords(q)\n",
        "    q_vec = tfidf_vectorizer.transform([q])\n",
        "    q_pred = clf.predict(q_vec)\n",
        "    return multilabel_binarizer.inverse_transform(q_pred)\n",
        "  \n",
        "for i in range(5): \n",
        "  k = xval.sample(1).index[0] \n",
        "  print(\"Movie: \", movies_new['movie_name'][k], \"\\nPredicted genre: \", infer_tags(xval[k])), print(\"Actual genre: \",movies_new['genre_new'][k], \"\\n\")\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42303it [00:00, 52566.50it/s]\n",
            "100%|██████████| 42303/42303 [00:00<00:00, 812709.92it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:118: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:152: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:76: UserWarning: Label not 48 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:76: UserWarning: Label not 182 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:76: UserWarning: Label not 214 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:76: UserWarning: Label not 245 is present in all training examples.\n",
            "  str(classes[c]))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Movie:  Shrimad Virat Veerabrahmendra Swami Charitra \n",
            "Predicted genre:  [('Drama',)]\n",
            "Actual genre:  ['History', 'Biographical film', 'Drama', 'Musical'] \n",
            "\n",
            "Movie:  The Corn is Green \n",
            "Predicted genre:  [('Drama',)]\n",
            "Actual genre:  ['Film adaptation', 'Drama', 'Television movie'] \n",
            "\n",
            "Movie:  Someone to Watch Over Me \n",
            "Predicted genre:  [()]\n",
            "Actual genre:  ['Crime Fiction', 'Thriller', 'Mystery', 'Drama', 'Suspense', 'Crime Thriller', 'Romantic drama'] \n",
            "\n",
            "Movie:  The Medallion \n",
            "Predicted genre:  [('Action', 'Action/Adventure')]\n",
            "Actual genre:  ['Thriller', 'Fantasy Adventure', 'Buddy film', 'Adventure', 'Action Comedy', 'Action/Adventure', 'Martial Arts Film', 'Fantasy', 'Comedy', 'Action', 'Chinese Movies'] \n",
            "\n",
            "Movie:  A Pure Country Gift \n",
            "Predicted genre:  [('Drama', 'Musical')]\n",
            "Actual genre:  ['Romantic drama', 'Romance Film', 'Drama'] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0iMlRS9LqTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}